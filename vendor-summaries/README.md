# Vendor Summaries Project

## Overview

This project involves creating a comprehensive data pipeline to generate detailed summaries for thousands of vendors in Valify's database. It combines web scraping, feature extraction, and AI-powered summary generation to create rich vendor profiles.

## Key Components

1. URL Collection: Gathered and verified over 8,500 vendor URLs
2. Web Scraping: Collaborated with a freelance team to develop and run a web scraping application
3. Feature Extraction: Created a script to extract key vendor information from scraped data
4. Summary Generation: Utilized Claude 3.5 Sonnet for final summary creation

## Technologies and Skills

- Python
- Web scraping techniques
- AWS services
- SQL and PostgreSQL
- LLM integration (Claude 3 Haiku and 3.5 Sonnet)
- Data pipeline development
- AutoHotkey for data entry automation

## Process Highlights

- Developed AutoHotkey scripts to streamline URL collection, saving significant time
- Implemented a two-step LLM process (Haiku for feature extraction, Sonnet for summaries) to optimize cost and accuracy
- Collaborated with developers to create an end-to-end data pipeline from web scraping to summary generation

## Key Achievements

- Reduced project costs to approximately 10% of the initial estimate through efficient LLM usage
- Successfully processed tens of thousands of vendor websites
- Created a scalable and repeatable process for vendor data extraction and summarization

## Setup and Usage

For detailed instructions on setting up and running the feature extraction process, please refer to the project's [full README](./README.md).

This project demonstrated my ability to work on complex, multi-stage data processing tasks and collaborate effectively with a development team to create efficient, AI-driven solutions.
